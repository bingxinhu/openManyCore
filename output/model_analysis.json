{
  "model_info": {
    "ir_version": 10,
    "opset_import": [
      "domain: \"\"\nversion: 20\n"
    ],
    "producer_name": "pytorch"
  },
  "computation_graph": {
    "nodes": [
      {
        "name": "node_conv2d",
        "type": "Conv",
        "inputs": [
          "input",
          "conv1.weight",
          "conv1.bias"
        ],
        "outputs": [
          "conv2d"
        ],
        "attributes": {
          "group": 1,
          "pads": [
            2,
            2,
            2,
            2
          ],
          "auto_pad": "NOTSET",
          "strides": [
            1,
            1
          ],
          "dilations": [
            1,
            1
          ]
        }
      },
      {
        "name": "node_relu",
        "type": "Relu",
        "inputs": [
          "conv2d"
        ],
        "outputs": [
          "relu"
        ],
        "attributes": {}
      },
      {
        "name": "node_avg_pool2d",
        "type": "AveragePool",
        "inputs": [
          "relu"
        ],
        "outputs": [
          "avg_pool2d"
        ],
        "attributes": {
          "count_include_pad": 1,
          "ceil_mode": 0,
          "pads": [
            0,
            0,
            0,
            0
          ],
          "auto_pad": "NOTSET",
          "strides": [
            2,
            2
          ],
          "kernel_shape": [
            2,
            2
          ]
        }
      },
      {
        "name": "node_conv2d_1",
        "type": "Conv",
        "inputs": [
          "avg_pool2d",
          "conv2.weight",
          "conv2.bias"
        ],
        "outputs": [
          "conv2d_1"
        ],
        "attributes": {
          "group": 1,
          "pads": [
            0,
            0,
            0,
            0
          ],
          "auto_pad": "NOTSET",
          "strides": [
            1,
            1
          ],
          "dilations": [
            1,
            1
          ]
        }
      },
      {
        "name": "node_relu_1",
        "type": "Relu",
        "inputs": [
          "conv2d_1"
        ],
        "outputs": [
          "relu_1"
        ],
        "attributes": {}
      },
      {
        "name": "node_avg_pool2d_1",
        "type": "AveragePool",
        "inputs": [
          "relu_1"
        ],
        "outputs": [
          "avg_pool2d_1"
        ],
        "attributes": {
          "count_include_pad": 1,
          "ceil_mode": 0,
          "pads": [
            0,
            0,
            0,
            0
          ],
          "auto_pad": "NOTSET",
          "strides": [
            2,
            2
          ],
          "kernel_shape": [
            2,
            2
          ]
        }
      },
      {
        "name": "node_view",
        "type": "Reshape",
        "inputs": [
          "avg_pool2d_1",
          "val_3"
        ],
        "outputs": [
          "view"
        ],
        "attributes": {
          "allowzero": 1
        }
      },
      {
        "name": "node_linear",
        "type": "Gemm",
        "inputs": [
          "view",
          "fc1.weight",
          "fc1.bias"
        ],
        "outputs": [
          "linear"
        ],
        "attributes": {
          "beta": 1.0,
          "transB": 1,
          "alpha": 1.0,
          "transA": 0
        }
      },
      {
        "name": "node_relu_2",
        "type": "Relu",
        "inputs": [
          "linear"
        ],
        "outputs": [
          "relu_2"
        ],
        "attributes": {}
      },
      {
        "name": "node_linear_1",
        "type": "Gemm",
        "inputs": [
          "relu_2",
          "fc2.weight",
          "fc2.bias"
        ],
        "outputs": [
          "linear_1"
        ],
        "attributes": {
          "beta": 1.0,
          "transB": 1,
          "alpha": 1.0,
          "transA": 0
        }
      },
      {
        "name": "node_relu_3",
        "type": "Relu",
        "inputs": [
          "linear_1"
        ],
        "outputs": [
          "relu_3"
        ],
        "attributes": {}
      },
      {
        "name": "node_linear_2",
        "type": "Gemm",
        "inputs": [
          "relu_3",
          "fc3.weight",
          "fc3.bias"
        ],
        "outputs": [
          "output"
        ],
        "attributes": {
          "beta": 1.0,
          "transB": 1,
          "alpha": 1.0,
          "transA": 0
        }
      }
    ],
    "tensors": {
      "conv1.weight": {
        "name": "conv1.weight",
        "shape": [
          6,
          1,
          5,
          5
        ],
        "dtype": "float32",
        "size_in_bytes": 600,
        "is_parameter": true,
        "data": "[[[[   6.  103.   81.   83.  106.]\n   [ -21.  -41.   52.    3.  -86.]\n   [-124. -128. -128.  -80. -128.]\n   [  24.  -35.  -94. -128.  -77.]\n   [ 101.  -10.   25.   24.   40.]]]\n\n\n [[[ -45.  -11.   82.  -18.  -49.]\n   [ -86.  -56.   80.   99.    1.]\n   [-108.  -66.   40.   83.   58.]\n   [-128. -128. -109.  -21.   41.]\n   [  42.  -80.  -77. -128.  -38.]]]\n\n\n [[[ -41.   32.  -17.  127.  -23.]\n   [  33.  -79.  -46.   21.  122.]\n   [  26.   -3.  -95. -128.  123.]\n   [ -21.  -25. -128.  -54.  127.]\n   [ -47.   84.  -33.   86.  -24.]]]\n\n\n [[[  80.  -70.  -97.  -46.   18.]\n   [ -28. -128.    2.  111.   38.]\n   [-128.  -80.  125.   53.  -72.]\n   [ -72.   41.  115.  -15.  -75.]\n   [  19.   27.    3. -128.  -64.]]]\n\n\n [[[ -15.  -15.  -69.  -62.   12.]\n   [ -67.  -64.  -41.  -64. -110.]\n   [ -60.   -2.    3.  -38.    1.]\n   [  29.  -46.   28.   86.   40.]\n   [  76.   84.   -3.   58.   40.]]]\n\n\n [[[   7.  -18.  -97. -105.  -33.]\n   [ -47.  -59. -128.  -26.  110.]\n   [   6.  -72. -128.  -16.   87.]\n   [  97.  -31. -122.  -62.   65.]\n   [ 114.   14.  -51.  -68.   20.]]]]",
        "data_type": "weight"
      },
      "conv1.bias": {
        "name": "conv1.bias",
        "shape": [
          6
        ],
        "dtype": "float32",
        "size_in_bytes": 24,
        "is_parameter": true,
        "data": "[ 6923.  6340. -5814.  5676.  2808.  6984.]",
        "data_type": "bias"
      },
      "conv2.weight": {
        "name": "conv2.weight",
        "shape": [
          16,
          6,
          5,
          5
        ],
        "dtype": "float32",
        "size_in_bytes": 9600,
        "is_parameter": true,
        "data": "[[[[ -18.   -5.  -11.   41.  -65.]\n   [  38.  -23.  -49.  -19.   -1.]\n   [ -42.  -41.  -15.   11.  -65.]\n   [ 102.   65.   14.   19.   19.]\n   [ -14.    2.   52.   14.   71.]]\n\n  [[ -55.  -43.   31.    9.  -16.]\n   [ -44.  -30.  -15.  -22.   36.]\n   [ -23.  -52.   17.  -19.    1.]\n   [  40.  -59.   54.   45.  -28.]\n   [ -24.  -17.  -28.   24.    6.]]\n\n  [[ -28.   -6.   -6.  -40.   -2.]\n   [ -40.   26.  -43.  -14.   35.]\n   [ -14.   62.   -1.  -60.   75.]\n   [  11.    0.    6.  -42.  -87.]\n   [  -5.    6.  -64.   11.  -64.]]\n\n  [[  38.   -1.   34.   -1.  -34.]\n   [  47.  -36.  -26.   22.  -10.]\n   [  12.  -37. -106.   -4.   57.]\n   [  -1.   35.  -21.  -76.  -29.]\n   [ -43.   15.   16.  -18.  -24.]]\n\n  [[   4.    7.   45.   32.  -33.]\n   [  46.   27.   18.  -57.  -73.]\n   [  -5.  -10.    4.   24.   26.]\n   [  53.   38.   40.   34.  -30.]\n   [ -29.  -31.  -28.  -89.  -46.]]\n\n  [[  -1.  -37.  -53.   60.    9.]\n   [ -18.   53.   52.   69.   16.]\n   [ -25.   48.   56.  -37.   32.]\n   [   4.   14.   -5.  -25.  -37.]\n   [  35.    3.  -17.   20.  -21.]]]\n\n\n [[[ -22.  -10.  -26.   -2.    3.]\n   [  -0.  -36.   46.   24.   30.]\n   [  31.   39.   15.  -35.   59.]\n   [ -49.  -57.   -3.  -37.   -8.]\n   [ -34.   12.   -4.  -58.  -38.]]\n\n  [[  38.   22.   12.    6.  -49.]\n   [  16.   22.   19.  -11.  -60.]\n   [ -35.  -62.  -76.   -5.  -45.]\n   [   3.   23.   11.   30.  -29.]\n   [  66.   64.    4.  -34.  -33.]]\n\n  [[ -10.  -54.  -46.  -55.   -6.]\n   [   8.   -7.   53.  -14.  -20.]\n   [  58.   18.  113.   13.   25.]\n   [  -4.   -2.  -17.   61.   24.]\n   [ -21.   30.   42.   35.  -19.]]\n\n  [[  34.  -34.  -52.   35.    3.]\n   [  27.   10.  -74.  -85.   13.]\n   [  -5.   69.   30.  -11.  -14.]\n   [  34.   60.   86.    8.   36.]\n   [ -59.   -2.  -23.   -2.  -42.]]\n\n  [[ -36.   31.   64.   33.  -32.]\n   [  -6.  -50.  -48.    1.   -1.]\n   [  18.   -5.   21.   31.  -33.]\n   [  12.   21.  -34.  -11.    1.]\n   [ -51.  -73.    4.    8.   12.]]\n\n  [[ -44.  -31.   42.   17.   -8.]\n   [ -25. -105. -117.  -56.  -18.]\n   [  27.  -87.  -48.  -37.   26.]\n   [ -14.    3.    2.  -25.   -8.]\n   [  17.  -20.  -56.  -12.  -26.]]]\n\n\n [[[ -18.  -36.  -30.  -34.  -65.]\n   [ -10.   28.    3.    3.  -85.]\n   [  28.   -7.  -37.  -91.    9.]\n   [ -35.   -1.  -35.   -1.   68.]\n   [ -12.    6.   -2.   13.  -12.]]\n\n  [[  33.   54.   69.   48.   38.]\n   [  67.   69.   59.    5.  -32.]\n   [  30.   -6.  -34.  -41.  -22.]\n   [  30.   46.   16.    4.    3.]\n   [ -23.   -8.  -13.  -21.   -2.]]\n\n  [[ -48.  -19.  -10.   -1.  -27.]\n   [  -8.   -5.   22.   54.  -24.]\n   [  -9.   49.   57.   45.  -98.]\n   [ -40.   21.   42.   -5.  -64.]\n   [  -9.   34.  -23. -108.   17.]]\n\n  [[  14.  -62.  -66.  -70.  -61.]\n   [  -0.  -20.  -47.    7.   19.]\n   [  19.   -8.   -4.   31.   57.]\n   [ -26.   26.  -37.   39.   -5.]\n   [ -49.   20.   39.   -2.  -75.]]\n\n  [[  23.   38.   33.    6.  -24.]\n   [  11.  -41.  -38.  -41.  -58.]\n   [  11.   35.   42.   41.  -40.]\n   [ -30.   14.   21.    9.  -44.]\n   [ -13.   51.    7.  -68.   11.]]\n\n  [[  44.   35.  -19.  -18.  -27.]\n   [  91.   20.  -37.   47.   32.]\n   [ -21.    7.   15.   33.   68.]\n   [   3.    2.   28.   15.    9.]\n   [  40.   11.   20.  -45.   51.]]]\n\n\n ...\n\n\n [[[  -9.   28.   44.  -26.  -41.]\n   [ -51.  -32.  -44.  -15.   61.]\n   [ -11.   11.  101.   66.   -4.]\n   [ -36.  -42.  -14.  -25.  -32.]\n   [  74.   37.   40.   28.   -8.]]\n\n  [[ -10.   12.  -27.  -55.   -6.]\n   [  -6.   22.  -10.   -7.  -32.]\n   [   7.   -3.   -9.  -15.    6.]\n   [   4.   -6.   47.   33.   17.]\n   [   9.   11.   23.    1.   48.]]\n\n  [[ -22.    6.   46.  -16.  -59.]\n   [  26.   14.  -17.  -38.   -6.]\n   [  -7.  -38.  -24.   37.  -18.]\n   [  16.   21.   -7.   14.  -25.]\n   [  32.   26.   -5.   18.   10.]]\n\n  [[  10.   22.  -22.  -32.    9.]\n   [  -4.    3.   25.   52.  -22.]\n   [ -24.   44.   18.   15.  -21.]\n   [  -5.  -51.   16.   67.   24.]\n   [ -21.  -31.  -26.    9.   16.]]\n\n  [[ -48.   -5.   18.   51.  -25.]\n   [ -15.   33.   15.  -56.  -60.]\n   [ -35.  -22.  -28.   15.    6.]\n   [ -54.  -27.   -9.   11.  -13.]\n   [  12.   42.   31.   12.  -16.]]\n\n  [[   4.  -27.  -18.   18.   18.]\n   [   4.   -6.  -33.  -61.  -42.]\n   [ -10.   18.  -39.  -35.  -29.]\n   [  -2.  -15.   -3.   64.   12.]\n   [  -2.  -16.   -1.    7.    7.]]]\n\n\n [[[  25.   56.    3.   24.    2.]\n   [   1.   29.  -12.  -28.    8.]\n   [ -33.  -25.   54.   49.   -9.]\n   [ -26.  -82.   12.   47.  -28.]\n   [   2.  -39.  -24.   13.   32.]]\n\n  [[ -25.   40.  -13.   10.    0.]\n   [   5.  -48.   43.   -5.  -13.]\n   [  47.  -31.   17.   77.   -6.]\n   [  43.   67.  -31.   -4.  -65.]\n   [ -21.   56.   59.   10.  -45.]]\n\n  [[   9.   24.   -6.   33.   33.]\n   [ -52.   15.  -16.    9.   14.]\n   [ -15.  -20.   25.   33.  -49.]\n   [  -9.  -67.  -32.   50.  -27.]\n   [  -5.   81.  -66.  -15.   -9.]]\n\n  [[  -1.   -8.   15.   29.   13.]\n   [ -44.   24.  -10.   -0.   41.]\n   [ -10.   40.   59.   -1.    8.]\n   [ -37.  -50.   -1.  -19.   -5.]\n   [ -12.  -16.  -55.   -1.  -14.]]\n\n  [[ -36.  -25.  -19.    8.   -0.]\n   [ -14.   -3.   58.   18.   12.]\n   [ -66.  -11.  -37.  -47.  -17.]\n   [ -71.  -31.    5.   37.   11.]\n   [  -5.  -20.  -26.    0.  -24.]]\n\n  [[  28.    4.  -60.  -11.  -41.]\n   [  28.   44.   -3.  -28.    7.]\n   [   2.    8.  -12.    8.  -14.]\n   [   3.   37.  -22.   50.  -45.]\n   [   0.   -8.  -40.    2.  -40.]]]\n\n\n [[[-119.  -33.  -12.  -22.    4.]\n   [   6.   24.  -22.    5.   53.]\n   [  34.   32.    7.   13.   12.]\n   [  51.   55.   38.  -19.   -6.]\n   [  -5.  -24.  -38.  -28.   -8.]]\n\n  [[  25.  -34.  -14.  -44.  -26.]\n   [  -9.   40.   19.  -56.  -10.]\n   [ -63.   -4.   -9.   22.   13.]\n   [ -25.    3.   -5.   36.   38.]\n   [ -41.  -11.   -8.  -17.  -28.]]\n\n  [[ -53.  -52.  -20.  -25.   27.]\n   [  16.   11.   34.   -8.    3.]\n   [  32.    2.   74.  -25.  -13.]\n   [  11.   44.    3.   -8.  -29.]\n   [  -6.   -6.  -38.  -10.  -63.]]\n\n  [[  -7.   19.   34.   26.   29.]\n   [ -49.  -24.    7.  -36.  -51.]\n   [   8.    7.  -43.  -19.   -4.]\n   [  13.   30.   41.   20.   31.]\n   [   6.   32.   13.   -2.   15.]]\n\n  [[  -2.   -7.   37.   38.  -15.]\n   [  20.   -4.    0.  -13.    1.]\n   [ -35.  -63.  -64.  -22.  -33.]\n   [ -29.  -69.  -17.  -37.  -27.]\n   [  31.   15.   38.   29.   31.]]\n\n  [[   8.   27.   10.  -13.   29.]\n   [ -50.  -51.    4.   18.   67.]\n   [ -44.  -61.  -17.    4.    9.]\n   [  -5.  -43.   14.    6.  -36.]\n   [  20.   16.    3.   19.    5.]]]]",
        "data_type": "weight"
      },
      "conv2.bias": {
        "name": "conv2.bias",
        "shape": [
          16
        ],
        "dtype": "float32",
        "size_in_bytes": 64,
        "is_parameter": true,
        "data": "[ -4258.   5403. -12362. -26637.  -3662.  12790.  16571. -17675.  11329.\n  -1398.   5074.  -9947.   -384.  -5640.  -4500.  -1129.]",
        "data_type": "bias"
      },
      "fc1.weight": {
        "name": "fc1.weight",
        "shape": [
          120,
          400
        ],
        "dtype": "float32",
        "size_in_bytes": 192000,
        "is_parameter": true,
        "data": "[[ 17.  -9.  -9. ...  32.  33. -70.]\n [-46. -13.  14. ...  15. -13. -38.]\n [-11. -50.   9. ... -69. -29.  15.]\n ...\n [-24.   2. 108. ...  -9.  43.  20.]\n [ 19. -33.  48. ...  15. -19.  53.]\n [ 31.  71. -48. ...  17.  16. -24.]]",
        "data_type": "weight"
      },
      "fc1.bias": {
        "name": "fc1.bias",
        "shape": [
          120
        ],
        "dtype": "float32",
        "size_in_bytes": 480,
        "is_parameter": true,
        "data": "[ -95021.    -744.  -17082.   -4749.   19560.  -38257.  -31397.  214693.\n   57484.  102525.  -55712.  114089.    8990.  -87570.  -16001.    4965.\n   28288.  -42922.  -37569.  -20181.  -19502.   87122.   40231.   47503.\n  -52919.   33976.  -78616.  -66567.   25025.    1022.  -97040.    7859.\n  -69396.   74640.  -40165.  -26848.   16248.   61948.   31291.    5870.\n  -45697.   63565.   -4117.  -95035.  -53290.   22434.   -6441.   97668.\n  -31721.  159468.  -84133.   85075.  -58186.  -55927.   52033.   40095.\n  -41584.  -30476.  -53014.   15979.   29052.   17517.   68625.   57215.\n    4488.  -18627.   12520.  -67634.  135031.   41987.  107824.  -19140.\n  -55906.  -17585.   20214.   40261.  -50067.   41621.  214469.  104380.\n   25602.   88718.  113250.   87059.   33593.   42577.     490. -127195.\n   15956.   10206.   65198.    8544.  -13597.   10265.  145515.   46342.\n   94377.  -31832.   94984.   -8815.  -42571.  -32142.   39401.  -87626.\n  -28296.  -19228.  -95358.  -29303. -107947.  -18747.     535.   64754.\n -156822.   66961.  -33933.   -1019. -100330. -111609.   66590.  -55002.]",
        "data_type": "bias"
      },
      "fc2.weight": {
        "name": "fc2.weight",
        "shape": [
          84,
          120
        ],
        "dtype": "float32",
        "size_in_bytes": 40320,
        "is_parameter": true,
        "data": "[[-28.  26. -42. ...   4.  54. -79.]\n [-22.   5.  13. ...  27.  22. -17.]\n [-31.  49.  -9. ...   5.  -5. -11.]\n ...\n [-27.  49.   1. ...   8.   3. -23.]\n [-24.  52.   4. ...  69. 102. -89.]\n [ -9. -57.  18. ...  41. -26.  -6.]]",
        "data_type": "weight"
      },
      "fc2.bias": {
        "name": "fc2.bias",
        "shape": [
          84
        ],
        "dtype": "float32",
        "size_in_bytes": 336,
        "is_parameter": true,
        "data": "[ 13354.  -1292.   9799.   1066.  -6449.  -1802.   -941.   3278.   -115.\n  13216.   4741.  -2832.  15254.   9934.   1848.  13442.  16535.    -51.\n -10428.  13964.  11170.   8267.    823.   2676.  22649.  -5312.  -4699.\n  10084.  15532.  14081.  19942.  -2636.   4144.  12679.  -8298.   3761.\n   9133.  11301.  11413.  21487.  19696.  11095.  19154. -11843.   7252.\n  13256.   1668.  23260.  13465.   9105.  14171.  13282.   2982.  -1499.\n   9753.  10283.  -8658.  10734.  -2130.  14790.   7972.  20429.  -4315.\n  15719.   1291.  11355.  10323.   1986.   -537.  20668.   6743.   9820.\n  14315.  -4020.  -2500.   9180.  11982.   3353.  18427.  11182.  -1215.\n  13291.  -2988.  12535.]",
        "data_type": "bias"
      },
      "fc3.weight": {
        "name": "fc3.weight",
        "shape": [
          10,
          84
        ],
        "dtype": "float32",
        "size_in_bytes": 3360,
        "is_parameter": true,
        "data": "[[ -40.  -62.  -11.  106.  100.  -58.  127.  -60.  -68.  -45.  -71.   54.\n   -88. -100.   24.  -77.  -89.  108.  -78. -122.  -56.   75.  -65.  -42.\n    66.  109.  -55.  -85.   72.  -88. -100.  121.  -98.  115.  125.  -71.\n   -55.  -35.  -51.  -63.  -52.  -87.  -54.  -47.  -56. -128.  112. -115.\n  -112.  108.  -49.   -7.  -91.  -54.  -56.  -68.  -87.  -75.  127.  -26.\n    99.  -69.  -78. -104.   71.   88.   43.  -76.  -38.  -39.  100.  -65.\n   -81.  122.  127.  111.   71.  -78.  -90.  -70.   98.  -90.  -10. -105.]\n [  89.   88.  105.  -88.  -58.   97.  -55.  107.  -77.   69.  -72. -118.\n   -37. -116.  -75.  -18.  -85.  -60.  110.   73.   66.   86.  -77.  -51.\n   -66.  -34.   13. -104. -109.   37.  -75.  -42.   77.  -34.   78.   31.\n   -92.  -47.  -57. -107.   98.   89.  -44.  117.  -16.  -37.  -84. -120.\n   -42.  -46.   89.  -70.  -47.   77.  -95.   92.  -72.  -94.   50.  -66.\n   -69. -126.  -62.  -35.  -39. -104.  -88.  112.  120.  -51.   45.  101.\n   -36.  -97.  115.  -74.  -28.   13.   30.  -94.   31.  105.  112.  -76.]\n [ -20.  -76. -109.  -93.  -93.  -80.  -42.   71.  -93. -100.  -79.  -72.\n   104.   16. -100.   74. -118.  101.  -63. -104.   86.   56.  -26.  -68.\n    81.  -17.  -67.   98. -109.   41.   88.   92.  -63.  -21.  -77.  127.\n   -35.   19.  -93.  123. -123.  -92. -123.  -52.  -97.   60.   93.   83.\n  -106.   11.   27.  -47.  -98.   27.  -76.  100.  -91.  -94. -122.    4.\n    70.  100.  -30.  -82.  -97.  -50.  103.  107. -110.   58.  -99.   61.\n    80.  -84.   33.   99.  -45.  118.  -92.    6.  -97. -108.  -32.  120.]\n [ -84.  -82.   93.  -69.  -52.  -44.  107.  -54. -113.  121.   75.  -55.\n    79. -110.   90.   76.   66.  -66.  -73. -126.  -30.  -87.  -64.  -55.\n    72.  -79.  -33.    8.   72.  -77.   74.  -86.  -25.   46.  -67.  -97.\n   107.  111.   92.   52.  104.  -64.   83.  -50.  125.  -79. -105. -105.\n    98.  -56. -100.  -51.  -70.  -62.  -28.   47.  -21.  123.  -88.   83.\n   -81.  -88.  -57.  -95.  -96.  -66.  -97.  -42.  -62.   96.  -92.   99.\n    73.  -75.  -71.  114.  -75.  -70. -106.  -85.  -88.   86.  -70.  -53.]\n [ 110.  -64.  -55.  -72.   63.  108.  -92.  -65.   92.  107.  116.   99.\n   -84.  -60.  -93. -114. -102.  -33.  -32.  -54.  -86.  -85.   -0.   57.\n   -87.  127.  111.  -67. -108.  -75. -103.   21.  -67.  -77.  -72.   99.\n   -55.  -17.  -26. -102.  -89.  -90.  -92.  127.  -78.   26.   78.   38.\n   -65.  -78.  -84.  -84.  104.   -8.  -32.  -74.  117.   54.  -56.  -79.\n   -78.   92.   83.   67.   48.  -93.  -45.  -55.   60. -105.  -95.   38.\n   108.   64.  -66.  -64.   88.  118.   82.   21.  -79.  -41.  -78.  -64.]\n [ -97.  100.   96. -104. -104.  -39.  -95.  -38.  127.  -90.  -66.  -87.\n    30.   99.   90.   98.   94.  -60.   91.  100.  -66.  -72.  -56.  -75.\n   -24.  107.  -55.  -47.   77.  -87. -117.  -63.  -92.  -45.  -99.  -74.\n    95.  -64.  -59.   84.   32.   19.  -86.  -53. -105.  -80.  -56. -102.\n    82.  -22.  -45.   89.  -48.  -95.  115.  -96.  -43.  -69.  -78.   88.\n   -97.  -99.   69. -123.  -32.  101.   29.  -23.  -64. -126.   89. -104.\n  -102.  109.  -60.  -41. -119.   21.   68.  103.  -95.   87.  -43.   -7.]\n [-120.  100.  -81.   88.  116.  -77.  -94.  -51.   88.  -76.   57.   79.\n    93.  -23.  101.  -99.    1.   97.  116.   69.  -64.  -89.  127.  -61.\n  -102. -117.  -54.  122.   49.  -37.  -69.  -71.  115.  -69.  113.  -32.\n   -81.  -60.  -58.   54.  -60.  -73.  -68.   49.  -52.   93. -106.  -94.\n    27.   32.  -86.  -78.  -59.  125.  -82.  -63.   86.  -15.  -59.  -81.\n    91.  -86.  -52. -104.   78. -105.  -74.  -51.  -59.  -58.   69.  -21.\n   -48.  -60. -108.  -93.  -78.   -6. -107. -126.   78.  -96.   55.  108.]\n [-125.  -12.  -79.   66.  -89.  -82.   -1.   65.   -0.  -40.  111.  -72.\n   -74.   78.  -72.  -68. -108. -105.  -84.  -98.  103.   89.  -95.   99.\n   -62. -126.  122.   83.  -79.   90.    7.   45.  -39.  -61.   -1.  -52.\n    46.  -90.  -87.  -77.  102.  -15.   60.  -99.  111.  -56.   34.   86.\n   -77.  -62.  112.  -85.   93.  -91.  118.   54.   99.   -7.  108.  114.\n   -90.  -75.  -75.   85.  -53.  103.  -42.  -98.  124.  -61.  -94.  -76.\n    -4.   39.   -7.  -92. -117.  -79. -115.  -37.  -58.  -87.  -76.  -81.]\n [  54.  -50.  -72. -109.  -81.  -58. -100.  -61.  -70.   29.  -73. -106.\n   -86.  -77.  -89. -112.   24.  -83.  -77.  107.  -86.  -30.  -79.  -91.\n    75.  -62.  -73.  -97.   16.  -90.   93.  -64.   75.   84.  -64. -118.\n  -128.  -79.  101.  -16.  -39.  109.  104.  -55. -101.  109.  -61.  102.\n   104.   90.   92.   99. -116. -110.  103.  -95.  -50.   94.  -71. -111.\n    80.   62. -105.  111.  106.  -75.  100.   20.  -35.   86.   41.  -80.\n   -81. -100.  -63.  -47.   61.  -68.   79.    1.   99.  -27.  -88.   55.]\n [  72.  -66.  -50.  108.   55.   78.  106.  -75.  -70.  -93. -119.   79.\n  -105.  108.  -75.   36.   97.  -53.  -73.  -57.  -77.  -96.  127.   96.\n   -74.  -65.  -82.  -80.  -95.   97.  -20.  -56.  -79.  -80.  -56.   19.\n     4.  122.   55.  -83. -128.   96.   76.  -96.   62.  -86.  -88.   15.\n   -84.  -38.  -90.   93.   82.  -36.  -88.  -56.  -88. -107.   58.  -85.\n   -55.   88.  100.   71. -128.   51. -111.  -38.  -86.   75. -126.  -98.\n   -54.  -33.  -49.  -39.   76. -124.   72.   89.  -68.  -26.  127.  -51.]]",
        "data_type": "weight"
      },
      "fc3.bias": {
        "name": "fc3.bias",
        "shape": [
          10
        ],
        "dtype": "float32",
        "size_in_bytes": 40,
        "is_parameter": true,
        "data": "[-480. 3246. 1588.  344.  152.  645. 1352. 2768. 3052.  664.]",
        "data_type": "bias"
      },
      "val_3": {
        "name": "val_3",
        "shape": [
          2
        ],
        "dtype": "int64",
        "size_in_bytes": 16,
        "is_parameter": true,
        "data": "[ 1 -1]",
        "data_type": "bias"
      },
      "input": {
        "name": "input",
        "shape": [
          1,
          1,
          28,
          28
        ],
        "dtype": "float32",
        "size_in_bytes": 3136,
        "is_parameter": false,
        "data": null,
        "data_type": "input"
      },
      "output": {
        "name": "output",
        "shape": [
          1,
          10
        ],
        "dtype": "float32",
        "size_in_bytes": 40,
        "is_parameter": false,
        "data": null,
        "data_type": "output"
      },
      "conv2d": {
        "name": "conv2d",
        "shape": [
          1,
          6,
          28,
          28
        ],
        "dtype": "float32",
        "size_in_bytes": 18816,
        "is_parameter": false,
        "is_intermediate": true,
        "data": null,
        "data_type": "intermediate"
      },
      "relu": {
        "name": "relu",
        "shape": [
          1,
          6,
          28,
          28
        ],
        "dtype": "float32",
        "size_in_bytes": 18816,
        "is_parameter": false,
        "is_intermediate": true,
        "data": null,
        "data_type": "intermediate"
      }
    },
    "inputs": [
      {
        "name": "input",
        "shape": [
          1,
          1,
          28,
          28
        ],
        "dtype": "float32"
      }
    ],
    "outputs": [
      {
        "name": "output",
        "shape": [
          1,
          10
        ],
        "dtype": "float32"
      }
    ]
  },
  "statistics": {
    "total_operators": 12,
    "total_tensors": 15,
    "total_parameters": 11,
    "total_parameters_size": 246840,
    "total_activations_size": 40808
  }
}