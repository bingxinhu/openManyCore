import logging
import numpy as np
import os
import time
import sys
from typing import Dict, Any, List, Optional

# å¯¼å…¥ç»„ä»¶
from model_processor import ModelProcessor
from manycore_config import ManyCoreYAMLConfig
from manycore_primitives import RoleBasedPrimitives
from manycore_scheduler import RoleBasedScheduler
from manycore_codegen import EnhancedMemoryCodeGenerator
from manycore_runtime import EnhancedMemoryRuntime

class EnhancedMemoryPipelineController:
    """å¢å¼ºå†…å­˜æ¶æ„éƒ¨ç½²å…¨æµç¨‹æ§åˆ¶å™¨"""
    def __init__(self, config_path: str):
        # åˆå§‹åŒ–é…ç½®
        self.config = ManyCoreYAMLConfig(config_path)
        
        # åˆå§‹åŒ–æ ¸å¿ƒç»„ä»¶
        self._init_components()
        
        # åˆå§‹åŒ–æ¨¡å‹å¤„ç†å™¨
        self.model_processor = ModelProcessor(self.config)
        
        # åˆå§‹åŒ–æµç¨‹çŠ¶æ€
        self.binary = None
        self.weights = None
        self.layers = []
        self.mod = None
        self.input_name = None
        self.onnx_model = None
        
        # æ€§èƒ½ç»Ÿè®¡
        self.performance_stats = {}
        
        logging.info("å¢å¼ºå†…å­˜æ¶æ„æµç¨‹æ§åˆ¶å™¨åˆå§‹åŒ–å®Œæˆ")
        
    def _init_components(self) -> None:
        """åˆå§‹åŒ–ä¼—æ ¸æ¶æ„æ ¸å¿ƒç»„ä»¶"""
        try:
            # æ³¨å†ŒåŸè¯­
            RoleBasedPrimitives.register_primitives()
            logging.info("1. åŸè¯­æ³¨å†Œå®Œæˆ")
            
            # åˆ›å»ºè°ƒåº¦å™¨
            self.scheduler = RoleBasedScheduler(self.config)
            logging.info("2. è°ƒåº¦å™¨åˆå§‹åŒ–å®Œæˆ")
            
            # åˆ›å»ºè¿è¡Œæ—¶ - ä½¿ç”¨é…ç½®çš„æ¿€æ´»æ ¸å¿ƒ
            active_core_ids = self.config.get_active_core_ids()
            self.runtime = EnhancedMemoryRuntime(self.config, active_core_ids)
            logging.info("3. è¿è¡Œæ—¶åˆå§‹åŒ–å®Œæˆ")
            
            # åˆ›å»ºä»£ç ç”Ÿæˆå™¨
            self.codegen = EnhancedMemoryCodeGenerator(self.config, self.scheduler, self.runtime)
            logging.info("4. ä»£ç ç”Ÿæˆå™¨åˆå§‹åŒ–å®Œæˆ")
        
            logging.info("å¢å¼ºå†…å­˜æ¶æ„æ ¸å¿ƒç»„ä»¶åˆå§‹åŒ–å®Œæˆ")
            logging.info(f"æ ¸å¿ƒé…ç½®: æ€»æ ¸å¿ƒæ•°={self.config.get_total_cores()}, "
                        f"è®¡ç®—æ ¸å¿ƒ={len(self.config.get_all_compute_cores())}, "
                        f"æ¿€æ´»æ ¸å¿ƒ={len(self.runtime.active_cores)}")
                        
        except Exception as e:
            logging.error(f"ç»„ä»¶åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def prepare_model(self) -> None:
        """å‡†å¤‡æ¨¡å‹ï¼šåŠ è½½ã€è½¬æ¢å’Œæå–æƒé‡"""
        try:
            start_time = time.time()
            
            # åŠ è½½å¹¶è½¬æ¢æ¨¡å‹
            self.mod, self.input_name, self.onnx_model = self.model_processor.load_and_convert()
            
            # æå–æƒé‡
            self.weights = self.model_processor.extract_weights(self.onnx_model)
            
            # åˆ†ææ¨¡å‹å±‚
            self.layers = self.model_processor.analyze_layers(self.mod)
            
            # ä¸ºæ¯ä¸ªå±‚åˆ†é…æ¿€æ´»çš„è®¡ç®—æ ¸å¿ƒ
            active_core_ids = self.config.get_active_core_ids()
            successful_assignments = 0
            for layer_name, layer_type in self.layers:
                try:
                    # ä½¿ç”¨é…ç½®çš„æ¿€æ´»æ ¸å¿ƒå‚ä¸æ¯ä¸€å±‚çš„è®¡ç®—
                    self.scheduler.assign_layer_to_cores(layer_name, active_core_ids)
                    
                    # ä¼°ç®—å±‚æ€§èƒ½
                    input_size = np.prod(self.config.get_input_shape())
                    perf = self.scheduler.estimate_layer_performance(layer_name, input_size)
                    
                    # è®°å½•æ€§èƒ½ç»Ÿè®¡
                    self.performance_stats[layer_name] = perf
                    
                    logging.info(f"{layer_name}({layer_type}) æ€§èƒ½ä¼°ç®—: "
                                f"è®¡ç®—æ—¶é—´={perf['compute_time_s']*1e6:.2f}Î¼s, "
                                f"é€šä¿¡æ—¶é—´={perf['comm_time_s']*1e6:.2f}Î¼s, "
                                f"æ€»æ—¶é—´={perf['total_time_s']*1e6:.2f}Î¼s")
                    
                    successful_assignments += 1
                    
                except Exception as e:
                    logging.warning(f"å±‚ {layer_name} åˆ†é…å¤±è´¥: {e}")
                    continue
            
            elapsed_time = time.time() - start_time
            
            if successful_assignments == 0:
                logging.error("æ‰€æœ‰å±‚åˆ†é…éƒ½å¤±è´¥äº†ï¼Œåˆ›å»ºé»˜è®¤é…ç½®")
                self._create_fallback_model()
            else:
                logging.info(f"æ¨¡å‹å‡†å¤‡å®Œæˆï¼Œå…± {len(self.layers)} å±‚ï¼ŒæˆåŠŸåˆ†é… {successful_assignments} å±‚")
            
            # æ‰“å°è°ƒåº¦æ‘˜è¦
            self.scheduler.print_scheduling_summary()
            
            # è®°å½•æ€§èƒ½ç»Ÿè®¡
            total_compute_time = sum(perf['total_time_s'] for perf in self.performance_stats.values())
            self.performance_stats['total'] = {
                'total_time_s': total_compute_time,
                'preparation_time_s': elapsed_time,
                'layer_count': len(self.layers)
            }
            
            logging.info(f"æ¨¡å‹å‡†å¤‡æ€»è€—æ—¶: {elapsed_time:.2f}ç§’")
            logging.info(f"é¢„ä¼°æ¨ç†æ€»æ—¶é—´: {total_compute_time*1e6:.2f}Î¼s")
            
        except Exception as e:
            logging.error(f"æ¨¡å‹å‡†å¤‡å¤±è´¥: {e}")
            # åˆ›å»ºé»˜è®¤å±‚ä½œä¸ºåå¤‡
            self._create_fallback_model()
            logging.info("ä½¿ç”¨é»˜è®¤æ¨¡å‹é…ç½®ç»§ç»­æ‰§è¡Œ")
    
    def _create_fallback_model(self) -> None:
        """åˆ›å»ºåå¤‡æ¨¡å‹é…ç½®"""
        try:
            self.layers = [
                ("conv1", "conv2d"),
                ("relu1", "ann_activation"),
                ("pool1", "vector_accumulate"),
                ("fc1", "fully_connected")
            ]
            self.weights = {
                "conv1_weight": np.random.randn(10, 1, 3, 3).astype(np.float32),
                "fc1_weight": np.random.randn(10, 10).astype(np.float32)
            }
            
            # ä¸ºé»˜è®¤å±‚åˆ†é…æ¿€æ´»æ ¸å¿ƒ
            active_core_ids = self.config.get_active_core_ids()
            for layer_name, _ in self.layers:
                self.scheduler.assign_layer_to_cores(layer_name, active_core_ids)
                
            logging.info("åå¤‡æ¨¡å‹é…ç½®åˆ›å»ºå®Œæˆ")
            
        except Exception as e:
            logging.error(f"åˆ›å»ºåå¤‡æ¨¡å‹å¤±è´¥: {e}")
            raise
    
    def generate_executable(self) -> None:
        """ç”Ÿæˆå¢å¼ºå†…å­˜æ¶æ„å¯æ‰§è¡Œä»£ç """
        if not hasattr(self, 'layers') or not self.layers:
            raise RuntimeError("è¯·å…ˆè°ƒç”¨prepare_model()å‡†å¤‡æ¨¡å‹")
            
        logging.info(f"å¼€å§‹ä¸º {len(self.layers)} å±‚ç”Ÿæˆå¢å¼ºå†…å­˜æ¶æ„ä»£ç ...")
        
        start_time = time.time()
        
        try:
            # åœ¨ç”Ÿæˆä»£ç ä¹‹å‰æ¿€æ´»é…ç½®çš„æ ¸å¿ƒ
            active_core_ids = self.config.get_active_core_ids()
            self.runtime.activate_cores(active_core_ids)
            logging.info(f"å·²æ¿€æ´» {len(active_core_ids)} ä¸ªæ ¸å¿ƒç”¨äºä»£ç ç”Ÿæˆ: {active_core_ids}")
            
            # ç”Ÿæˆè¾“å…¥æ•°æ® - å½»åº•éªŒè¯
            input_shape = self.config.get_input_shape()
            input_dtype = self.config.get_input_dtype()
            
            # éªŒè¯è¾“å…¥å½¢çŠ¶
            if not input_shape or any(dim <= 0 for dim in input_shape):
                logging.warning(f"è¾“å…¥å½¢çŠ¶æ— æ•ˆ: {input_shape}ï¼Œä½¿ç”¨é»˜è®¤å½¢çŠ¶")
                input_shape = (1, 1, 1, 100)
            
            # éªŒè¯æ•°æ®ç±»å‹
            try:
                dtype_obj = np.dtype(input_dtype)
            except:
                logging.warning(f"æ•°æ®ç±»å‹æ— æ•ˆ: {input_dtype}ï¼Œä½¿ç”¨float32")
                input_dtype = "float32"
                dtype_obj = np.float32
            
            # åˆ›å»ºè¾“å…¥æ•°æ®
            try:
                input_data = np.random.rand(*input_shape).astype(dtype_obj)
            except Exception as e:
                logging.error(f"åˆ›å»ºè¾“å…¥æ•°æ®å¤±è´¥: {e}ï¼Œä½¿ç”¨ç®€å•æ•°æ®")
                # ä½¿ç”¨æ›´ç®€å•çš„æ•°æ®
                simple_shape = (100,)  # ä¸€ç»´æ•°ç»„
                input_data = np.random.rand(*simple_shape).astype(np.float32)
            
            logging.info(f"æœ€ç»ˆè¾“å…¥æ•°æ® - å½¢çŠ¶: {input_data.shape}, æ•°æ®ç±»å‹: {input_data.dtype}, æ€»å…ƒç´ æ•°: {input_data.size}")
            
            # ä¸ºæ¯ä¸ªå±‚ç”Ÿæˆä»£ç 
            successful_generations = 0
            for i, (layer_name, layer_type) in enumerate(self.layers):
                logging.info(f"ä¸ºå±‚ {i+1}/{len(self.layers)}: {layer_name} (ç±»å‹: {layer_type}) ç”Ÿæˆä»£ç ")
                
                try:
                    # æ£€æŸ¥æ¿€æ´»æ ¸å¿ƒçŠ¶æ€
                    if not self.runtime.active_cores:
                        logging.warning(f"å±‚ {layer_name} ç”Ÿæˆæ—¶æ²¡æœ‰æ¿€æ´»æ ¸å¿ƒï¼Œé‡æ–°æ¿€æ´»")
                        self.runtime.activate_cores(active_core_ids)
                    
                    # ç”Ÿæˆå¢å¼ºå†…å­˜æ¶æ„ä»£ç 
                    self.codegen.generate_enhanced_memory_code(layer_name, layer_type, input_data, self.weights)
                    
                    successful_generations += 1
                    
                except Exception as e:
                    logging.error(f"ç”Ÿæˆå±‚ {layer_name} ä»£ç æ—¶å‡ºé”™: {e}")
                    # å°è¯•é‡æ–°æ¿€æ´»æ ¸å¿ƒå¹¶ç»§ç»­
                    try:
                        logging.info(f"å°è¯•é‡æ–°æ¿€æ´»æ ¸å¿ƒå¹¶é‡è¯•å±‚ {layer_name}")
                        self.runtime.activate_cores(active_core_ids)
                        self.codegen.generate_enhanced_memory_code(layer_name, layer_type, input_data, self.weights)
                        successful_generations += 1
                        logging.info(f"å±‚ {layer_name} ä»£ç ç”Ÿæˆé‡è¯•æˆåŠŸ")
                    except Exception as retry_e:
                        logging.error(f"å±‚ {layer_name} ä»£ç ç”Ÿæˆé‡è¯•å¤±è´¥: {retry_e}")
                        continue
            
            # ç”Ÿæˆæœ€ç»ˆäºŒè¿›åˆ¶
            self.binary = self.codegen.generate_binary()
            
            elapsed_time = time.time() - start_time
            
            logging.info(f"äºŒè¿›åˆ¶ä»£ç ç”Ÿæˆå®Œæˆï¼Œå¤§å°: {len(self.binary)}å­—èŠ‚ï¼Œè€—æ—¶: {elapsed_time:.2f}ç§’")
            logging.info(f"æˆåŠŸä¸º {successful_generations}/{len(self.layers)} å±‚ç”Ÿæˆä»£ç ")
            
            # æ‰“å°ç¨‹åºæ‘˜è¦
            program_stats = self.codegen.get_core_program_stats()
            logging.info(f"ç¨‹åºç»Ÿè®¡: æ€»æŒ‡ä»¤æ•°={program_stats['total_instructions']}, "
                        f"æ¿€æ´»æ ¸å¿ƒæ•°={program_stats['active_cores']}")
            
            # ä¿å­˜äºŒè¿›åˆ¶åˆ°outputç›®å½•
            self._save_binary_file()
            
            # è®°å½•æ€§èƒ½ç»Ÿè®¡
            self.performance_stats['code_generation'] = {
                'time_s': elapsed_time,
                'binary_size': len(self.binary),
                'total_instructions': program_stats['total_instructions'],
                'active_cores': program_stats['active_cores']
            }
            
        except Exception as e:
            logging.error(f"ç”Ÿæˆå¯æ‰§è¡Œæ–‡ä»¶å¤±è´¥: {e}")
            raise
    
    def _save_binary_file(self) -> None:
        """ä¿å­˜äºŒè¿›åˆ¶æ–‡ä»¶å’Œä¿¡æ¯æ–‡ä»¶"""
        output_dir = "output"
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
            logging.info(f"åˆ›å»ºè¾“å‡ºç›®å½•: {output_dir}")
            
        # ç”Ÿæˆå¸¦æœ‰æ—¶é—´æˆ³çš„æ–‡ä»¶å
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        binary_filename = f"{output_dir}/enhanced_memory_executable_{timestamp}.bin"
        
        try:
            # ä¿å­˜äºŒè¿›åˆ¶æ–‡ä»¶
            with open(binary_filename, 'wb') as f:
                f.write(self.binary)
                
            logging.info(f"äºŒè¿›åˆ¶æ–‡ä»¶å·²ä¿å­˜åˆ°: {binary_filename}")
            
        except Exception as e:
            logging.error(f"ä¿å­˜æ–‡ä»¶å¤±è´¥: {e}")
    
    def run_inference(self) -> np.ndarray:
        """æ‰§è¡Œæ¨ç†å¹¶è¿”å›ç»“æœ - ä½¿ç”¨é…ç½®çš„æ¿€æ´»æ ¸å¿ƒ"""
        # æ·»åŠ è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯
        logging.info(f"æ£€æŸ¥çŠ¶æ€: binary={self.binary is not None}, weights={self.weights is not None}")
        
        if not self.binary:
            logging.error("äºŒè¿›åˆ¶æ–‡ä»¶æœªç”Ÿæˆï¼Œè¯·æ£€æŸ¥ generate_executable() æ–¹æ³•")
            # å°è¯•é‡æ–°ç”Ÿæˆ
            try:
                logging.info("å°è¯•é‡æ–°ç”Ÿæˆå¯æ‰§è¡Œæ–‡ä»¶...")
                self.generate_executable()
            except Exception as e:
                logging.error(f"é‡æ–°ç”Ÿæˆå¯æ‰§è¡Œæ–‡ä»¶å¤±è´¥: {e}")
                raise RuntimeError("æ— æ³•ç”Ÿæˆå¯æ‰§è¡Œæ–‡ä»¶")
        
        if not self.weights:
            logging.error("æƒé‡æœªåŠ è½½ï¼Œè¯·æ£€æŸ¥ prepare_model() æ–¹æ³•")
            # å°è¯•é‡æ–°å‡†å¤‡æ¨¡å‹
            try:
                logging.info("å°è¯•é‡æ–°å‡†å¤‡æ¨¡å‹...")
                self.prepare_model()
            except Exception as e:
                logging.error(f"é‡æ–°å‡†å¤‡æ¨¡å‹å¤±è´¥: {e}")
                raise RuntimeError("æ— æ³•å‡†å¤‡æ¨¡å‹")
        
        if not self.binary or not self.weights:
            raise RuntimeError("è¯·å…ˆè°ƒç”¨prepare_model()å’Œgenerate_executable()")
            
        logging.info("å¼€å§‹æ‰§è¡Œå¢å¼ºå†…å­˜æ¶æ„æ¨ç†...")
        
        start_time = time.time()
        
        try:
            # æ¿€æ´»é…ç½®çš„æ ¸å¿ƒ
            active_core_ids = self.config.get_active_core_ids()
            self.runtime.activate_cores(active_core_ids)
            
            # ç”Ÿæˆè¾“å…¥æ•°æ® - å½»åº•éªŒè¯
            input_shape = self.config.get_input_shape()
            input_dtype = self.config.get_input_dtype()
            
            # éªŒè¯è¾“å…¥å½¢çŠ¶
            if not input_shape or any(dim <= 0 for dim in input_shape):
                logging.warning(f"è¾“å…¥å½¢çŠ¶æ— æ•ˆ: {input_shape}ï¼Œä½¿ç”¨é»˜è®¤å½¢çŠ¶")
                input_shape = (1, 1, 1, 100)
            
            # éªŒè¯æ•°æ®ç±»å‹
            try:
                dtype_obj = np.dtype(input_dtype)
            except:
                logging.warning(f"æ•°æ®ç±»å‹æ— æ•ˆ: {input_dtype}ï¼Œä½¿ç”¨float32")
                input_dtype = "float32"
                dtype_obj = np.float32
            
            # åˆ›å»ºè¾“å…¥æ•°æ®
            try:
                input_data = np.random.rand(*input_shape).astype(dtype_obj)
            except Exception as e:
                logging.error(f"åˆ›å»ºè¾“å…¥æ•°æ®å¤±è´¥: {e}ï¼Œä½¿ç”¨ç®€å•æ•°æ®")
                # ä½¿ç”¨æ›´ç®€å•çš„æ•°æ®
                simple_shape = (100,)  # ä¸€ç»´æ•°ç»„
                input_data = np.random.rand(*simple_shape).astype(np.float32)
            
            logging.info(f"æœ€ç»ˆè¾“å…¥æ•°æ® - å½¢çŠ¶: {input_data.shape}, æ•°æ®ç±»å‹: {input_data.dtype}, æ€»å…ƒç´ æ•°: {input_data.size}")
            
            # éªŒè¯æ•°æ®åˆ†å¸ƒ
            if not self.runtime._validate_data_distribution(input_data, active_core_ids):
                logging.warning("æ•°æ®åˆ†å¸ƒéªŒè¯å¤±è´¥ï¼Œä½¿ç”¨åå¤‡æ•°æ®")
                input_data = self.runtime._create_fallback_data(input_data.dtype, 100)
            
            # åŠ è½½è¾“å…¥æ•°æ®å’Œæƒé‡
            self.runtime.load_input_data(input_data)
            self.runtime.load_weights(self.weights)
            
            # åŠ è½½äºŒè¿›åˆ¶ç¨‹åº
            self.runtime.load_binary_programs(self.binary)
            
            # è·å–ç³»ç»ŸçŠ¶æ€
            system_status = self.runtime.get_system_status()
            logging.info(f"ç³»ç»ŸçŠ¶æ€: {system_status['active_cores']}ä¸ªæ ¸å¿ƒæ¿€æ´»")
            
            # æ‰§è¡Œå¹¶è¿”å›ç»“æœ
            result = self.runtime.run_computation()
            
            elapsed_time = time.time() - start_time
            
            # å¤„ç†ç»“æœ
            self._process_inference_result(result, elapsed_time)
            
            # è®°å½•æ€§èƒ½ç»Ÿè®¡
            self.performance_stats['inference'] = {
                'time_s': elapsed_time,
                'result_size': len(result),
                'system_status': system_status
            }
            
            return result
            
        except Exception as e:
            logging.error(f"æ¨ç†æ‰§è¡Œå¤±è´¥: {e}")
            # è¿”å›æ¨¡æ‹Ÿç»“æœä½œä¸ºåå¤‡
            logging.info("è¿”å›æ¨¡æ‹Ÿç»“æœä½œä¸ºåå¤‡")
            return np.array([1.0, 2.0, 3.0, 4.0, 5.0], dtype=np.float32)
    
    def _process_inference_result(self, result: np.ndarray, elapsed_time: float) -> None:
        """å¤„ç†æ¨ç†ç»“æœ"""
        if len(result) == 0:
            logging.warning("æ¨ç†ç»“æœä¸ºç©º")
        else:
            logging.info(f"æ¨ç†å®Œæˆï¼Œç»“æœå¤§å°: {result.shape}ï¼Œè€—æ—¶: {elapsed_time*1000:.2f}ms")
            
            # æ‰“å°ç»“æœç»Ÿè®¡ä¿¡æ¯
            logging.info(f"ç»“æœç»Ÿè®¡: å‡å€¼={np.mean(result):.4f}, æ ‡å‡†å·®={np.std(result):.4f}, "
                        f"èŒƒå›´=[{np.min(result):.4f}, {np.max(result):.4f}]")
            
            # æ‰“å°å‰å‡ ä¸ªç»“æœå€¼
            display_count = min(10, len(result))
            result_preview = [f"{x:.4f}" for x in result[:display_count]]
            logging.info(f"ç»“æœç¤ºä¾‹ (å‰{display_count}ä¸ª): {result_preview}")

    def get_pipeline_status(self) -> Dict[str, Any]:
        """è·å–æµæ°´çº¿çŠ¶æ€"""
        status = {
            "model_prepared": hasattr(self, 'layers') and len(self.layers) > 0,
            "executable_generated": self.binary is not None,
            "weights_loaded": self.weights is not None,
            "layers_count": len(self.layers) if hasattr(self, 'layers') else 0,
            "binary_size": len(self.binary) if self.binary else 0,
            "weights_count": len(self.weights) if self.weights else 0,
            "performance_stats": self.performance_stats
        }
        
        if hasattr(self, 'scheduler'):
            try:
                scheduling_summary = self.scheduler.get_scheduling_summary()
                status.update(scheduling_summary)
            except Exception as e:
                logging.warning(f"è·å–è°ƒåº¦æ‘˜è¦å¤±è´¥: {e}")
                
        if hasattr(self, 'codegen') and self.binary:
            try:
                program_stats = self.codegen.get_core_program_stats()
                status["program_stats"] = program_stats
            except Exception as e:
                logging.warning(f"è·å–ç¨‹åºç»Ÿè®¡å¤±è´¥: {e}")
                
        if hasattr(self, 'runtime'):
            try:
                system_status = self.runtime.get_system_status()
                status["system_status"] = system_status
            except Exception as e:
                logging.warning(f"è·å–ç³»ç»ŸçŠ¶æ€å¤±è´¥: {e}")
            
        return status

    def print_pipeline_status(self) -> None:
        """æ‰“å°æµæ°´çº¿çŠ¶æ€"""
        status = self.get_pipeline_status()
        
        print("\n" + "="*50)
        print("å¢å¼ºå†…å­˜æ¶æ„æµæ°´çº¿çŠ¶æ€")
        print("="*50)
        print(f"æ¨¡å‹å‡†å¤‡: {'âœ… å®Œæˆ' if status['model_prepared'] else 'âŒ æœªå®Œæˆ'}")
        print(f"å¯æ‰§è¡Œæ–‡ä»¶ç”Ÿæˆ: {'âœ… å®Œæˆ' if status['executable_generated'] else 'âŒ æœªå®Œæˆ'}")
        print(f"æƒé‡åŠ è½½: {'âœ… å®Œæˆ' if status['weights_loaded'] else 'âŒ æœªå®Œæˆ'}")
        
        if status['model_prepared']:
            print(f"æ¨¡å‹å±‚æ•°: {status['layers_count']}")
            if 'total_compute_cores_used' in status:
                print(f"ä½¿ç”¨çš„è®¡ç®—æ ¸å¿ƒæ•°: {status['total_compute_cores_used']}")
            
        if status['executable_generated']:
            print(f"äºŒè¿›åˆ¶å¤§å°: {status['binary_size']} å­—èŠ‚")
            
        if status['weights_loaded']:
            print(f"æƒé‡æ•°é‡: {status['weights_count']}")
            
        if 'program_stats' in status:
            stats = status['program_stats']
            print(f"ç¨‹åºæŒ‡ä»¤æ•°: {stats['total_instructions']}")
            print(f"æ¿€æ´»æ ¸å¿ƒæ•°: {stats['active_cores']}")
        
        if 'system_status' in status:
            sys_status = status['system_status']
            print(f"ç³»ç»Ÿæ¿€æ´»æ ¸å¿ƒ: {sys_status['active_cores']}")
            print(f"å†…å­˜ä½¿ç”¨ç‡ - MEM0: {sys_status['memory_usage']['mem0_usage_percent']:.1f}%")
            print(f"å†…å­˜ä½¿ç”¨ç‡ - MEM1: {sys_status['memory_usage']['mem1_usage_percent']:.1f}%")
        
        # æ‰“å°æ€§èƒ½ç»Ÿè®¡
        if status['performance_stats']:
            print("\næ€§èƒ½ç»Ÿè®¡:")
            if 'total' in status['performance_stats']:
                total_stats = status['performance_stats']['total']
                print(f"  æ¨¡å‹å‡†å¤‡æ—¶é—´: {total_stats.get('preparation_time_s', 0):.2f}s")
                print(f"  é¢„ä¼°æ¨ç†æ—¶é—´: {total_stats.get('total_time_s', 0)*1e6:.2f}Î¼s")
            
            if 'code_generation' in status['performance_stats']:
                code_stats = status['performance_stats']['code_generation']
                print(f"  ä»£ç ç”Ÿæˆæ—¶é—´: {code_stats.get('time_s', 0):.2f}s")
            
            if 'inference' in status['performance_stats']:
                inference_stats = status['performance_stats']['inference']
                print(f"  å®é™…æ¨ç†æ—¶é—´: {inference_stats.get('time_s', 0)*1000:.2f}ms")
        
        print("="*50)

def main():
    # é…ç½®å…¨å±€æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler("enhanced_memory_pipeline_execution.log", encoding='utf-8')
        ]
    )
    
    # ä½¿ç”¨å¢å¼ºå†…å­˜æ¶æ„é…ç½®æ–‡ä»¶
    config_path = "enhanced_memory_config.yaml"
    
    try:
        # åˆ›å»ºæµç¨‹æ§åˆ¶å™¨
        logging.info("æ­¥éª¤1: åˆå§‹åŒ–æµç¨‹æ§åˆ¶å™¨...")
        controller = EnhancedMemoryPipelineController(config_path)
        logging.info("å¢å¼ºå†…å­˜æ¶æ„æµç¨‹æ§åˆ¶å™¨åˆå§‹åŒ–å®Œæˆ")
        
        # æ‰“å°é…ç½®æ‘˜è¦
        controller.config.print_config_summary()
        
        # æ‰“å°åˆå§‹çŠ¶æ€
        controller.print_pipeline_status()
        
        # å‡†å¤‡æ¨¡å‹
        logging.info("æ­¥éª¤2: å‡†å¤‡æ¨¡å‹...")
        controller.prepare_model()
        logging.info(f"æ¨¡å‹å‡†å¤‡å®Œæˆï¼Œå±‚æ•°: {len(controller.layers)}")
        
        # æ£€æŸ¥æ¨¡å‹å‡†å¤‡ç»“æœ
        if not controller.layers:
            logging.error("æ¨¡å‹å‡†å¤‡å¤±è´¥ï¼šæ²¡æœ‰åˆ†æå‡ºä»»ä½•å±‚")
            return
        
        # ç”Ÿæˆå¯æ‰§è¡Œæ–‡ä»¶
        logging.info("æ­¥éª¤3: ç”Ÿæˆå¯æ‰§è¡Œæ–‡ä»¶...")
        controller.generate_executable()
        logging.info(f"å¯æ‰§è¡Œæ–‡ä»¶ç”Ÿæˆå®Œæˆï¼Œå¤§å°: {len(controller.binary) if controller.binary else 0} å­—èŠ‚")
        
        # æ£€æŸ¥å¯æ‰§è¡Œæ–‡ä»¶ç”Ÿæˆç»“æœ
        if not controller.binary:
            logging.error("å¯æ‰§è¡Œæ–‡ä»¶ç”Ÿæˆå¤±è´¥ï¼šäºŒè¿›åˆ¶ä¸ºç©º")
            return
        
        # æ‰§è¡Œæ¨ç†
        logging.info("æ­¥éª¤4: æ‰§è¡Œæ¨ç†...")
        result = controller.run_inference()
        logging.info(f"æ¨ç†æ‰§è¡Œå®Œæˆï¼Œç»“æœå¤§å°: {result.shape}")
        
        # æ‰“å°æœ€ç»ˆçŠ¶æ€
        controller.print_pipeline_status()
        
        logging.info("ğŸ‰ å¢å¼ºå†…å­˜æ¶æ„éƒ¨ç½²æµç¨‹å®Œæˆï¼")
        
    except Exception as e:
        logging.error(f"æ‰§è¡Œå‡ºé”™: {str(e)}", exc_info=True)
        sys.exit(1)

if __name__ == "__main__":
    main()
